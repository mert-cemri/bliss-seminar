<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Angela Zhou (UC Berkeley)</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Seminar&nbsp;home</a></div>
<div class="menu-item"><a href="past.html">Past&nbsp;Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Angela Zhou (UC Berkeley)</h1>
</div>
<p>Oct 29, 2021</p>
<h2>Title and Abstract</h2>
<p><b>Robust Policy Learning and Evaluation under Unobserved Confounding</b><br />
<br /></p>
<p>We study the problem of learning (single-timestep) personalized decision policies from observational data while accounting for possible unobserved confounding. Previous approaches, which assume unconfoundedness, that is, that no unobserved confounders affect both the treatment assignment as well as outcome, can lead to policies that introduce harm rather than benefit when some unobserved confounding is present as is generally the case with observational data. Instead, because policy value and regret may not be point-identifiable, we study a method that minimizes the worst-case estimated regret of a candidate policy against a baseline policy over an uncertainty set for propensity weights that controls the extent of unobserved confounding. Our uncertainty sets are superpopulation versions of sensitivity analysis in causal inference. We prove generalization guarantees that ensure our policy is safe when applied in practice and in fact obtains the best possible uniform control on the range of all possible population regrets that agree with the possible extent of confounding. We develop efficient algorithmic solutions to compute this minimax-optimal policy. Finally, we assess and compare our methods on synthetic and semisynthetic data; including a case study on personalizing hormone replacement therapy based on observational data in which we illustrate our results on a randomized experiment. </p>
<p>I will also discuss follow-up work for robust off-policy evaluation from infinite-horizon Markov decision processes. We consider stationary or baseline unobserved confounding and compute bounds by optimizing over the set of all stationary state-occupancy ratios that agree with a new partially identified estimating equation and the sensitivity model.</p>
<p>This is based on joint work with Nathan Kallus and Xiaojie Mao. Related papers: <a href="1" target=&ldquo;blank&rdquo;>1</a>, <a href="2" target=&ldquo;blank&rdquo;>2</a></p>
<h2>Bio</h2>
<p>Angela Zhou is a postdoc at UC Berkeley and will be a research fellow at the Simons program on Causality. Starting 2022 she will be an Assistant Professor of Data Sciences and Operations at the Marshall School of Business, University of Southern California. She works broadly on statistical machine learning for data-driven decision-making, with particular attention to research challenges and opportunities from practical data environments</p>
<div id="footer">
<div id="footer-text">
Page generated 2022-02-24 05:41:53 PST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
