<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Suvrit Sra (MIT)</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Seminar&nbsp;home</a></div>
<div class="menu-item"><a href="past.html">Past&nbsp;Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Suvrit Sra (MIT)</h1>
</div>
<p>Nov 12, 2021</p>
<h2>Title and Abstract</h2>
<p><b>Some surprising gaps between optimization theory and ML practice</b><br />
<br /></p>
<p>It is well-known that there are large gaps between optimization theory and machine learning practice. Even more surprising are, however, some gaps that have persisted at the fundamental level of how we analyze non-convex optimization in machine learning. I will talk about two such gaps in this talk. The first one pertains to ignoring the elephant in the room: non-differentiable non-convex optimization (e.g., training a deep ReLU network), and the second one to a surprising non-convergence phenomenon in the training of deep networks, which challenges existing theory and suggests a new direction of research. I will talk about some of our theoretical progress towards addressing these gaps, while highlighting important research questions.</p>
<p>Talk based on the PhD thesis of Jingzhao Zhang (MIT).</p>
<h2>Bio</h2>
<p>Suvrit Sra is an Associate Professor in the EECS Department at MIT, and also a core faculty member of the Laboratory for Information and Decision Systems (LIDS), the Institute for Data, Systems, and Society (IDSS), as well as a member of MIT-ML and Statistics groups. He obtained his PhD in Computer Science from the University of Texas at Austin. Before moving to MIT, he was a Senior Research Scientist at the Max Planck Institute for Intelligent Systems, Tübingen, Germany. He has held visiting faculty positions at UC Berkeley (EECS) and Carnegie Mellon University (Machine Learning Department) during 2013-2014. His research bridges a number of mathematical areas such as differential geometry, matrix analysis, convex analysis, probability theory, and optimization with machine learning. He founded the OPT (Optimization for Machine Learning) series of workshops, held from OPT2008–2017 at the NeurIPS (erstwhile NIPS) conference. He has co-edited a book with the same name (MIT Press, 2011). He is also a co-founder and chief scientist of macro-eyes, a global healthcare+AI startup</p>
<div id="footer">
<div id="footer-text">
Page generated 2022-03-17 10:17:23 PDT, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
