<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Steven Wu (UMN)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="../index.html">Seminar&nbsp;home</a></div>
<div class="menu-item"><a href="../past.html">Past&nbsp;Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Steven Wu (UMN)</h1>
</div>
<p>Apr 15.</p>
<h2>Title and Abstract</h2>
<p><b>How to Use Heuristics for Differential Privacy</b> <br />
We develop theory for using heuristics to solve computationally hard problems in differential privacy. Heuristic approaches have enjoyed tremendous success in machine learning, for which performance can be empirically evaluated. However, privacy guarantees cannot be evaluated empirically, and must be proven &#8201;&mdash;&#8201; without making heuristic assumptions. We show that learning problems over broad classes of functions can be solved privately and efficiently, assuming the existence of a non-private oracle for solving the same problem. Our first algorithm yields a privacy guarantee that is contingent on the correctness of the oracle. We then give a reduction which applies to a class of heuristics which we call certifiable, which allows us to convert oracle-dependent privacy guarantees to worst-case privacy guarantee that hold even when the heuristic standing in for the oracle might fail in adversarial ways. Finally, we consider a broad class of functions that includes most classes of simple boolean functions studied in the PAC learning literature, including conjunctions, disjunctions, parities, and discrete halfspaces. We show that there is an efficient algorithm for privately constructing synthetic data for any such class, given a non-private learning oracle. This in particular gives the first oracle-efficient algorithm for privately generating synthetic data for contingency tables. The most intriguing question left open by our work is whether or not every problem that can be solved differentially privately can be privately solved with an oracle-efficient algorithm. While we do not resolve this, we give a barrier result that suggests that any generic oracle-efficient reduction must fall outside of a natural class of algorithms (which includes the algorithms given in this paper).</p>
<h2>Bio</h2>
<p>Steven Wu is an Assistant Professor in computer science at the University of Minnesota. During 2017-2018, he was a post-doc researcher at Microsoft Research-New York City. Before that he received his PhD in computer science at the University of Pennsylvania, where he was co-advised by Michael Kearns and Aaron Roth. His research interests lie in algorithms and machine learning, especially in the areas of privacy-preserving data analysis, fairness in machine learning, and algorithmic economics. He is the recipient of a Google Faculty Research Award, a J.P. Morgan Faculty Award, and the Morris and Dorothy Rubinoff Dissertation Award</p>
<div id="footer">
<div id="footer-text">
Page generated 2019-07-25 11:13:45 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
