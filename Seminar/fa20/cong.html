<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Cong Ma (UC Berkeley)</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Seminar&nbsp;home</a></div>
<div class="menu-item"><a href="past.html">Past&nbsp;Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Cong Ma (UC Berkeley)</h1>
</div>
<p>Nov 6, 2020</p>
<h2>Title and Abstract</h2>
<p><b>Bridging convex and nonconvex optimization in noisy matrix completion: Stability and uncertainty quantification</b><br />
<br /></p>
<p>This talk is concerned with noisy matrix completion: given partial and corrupted entries of a large low-rank matrix, how to estimate and infer the underlying matrix? Arguably one of the most popular paradigms to tackle this problem is convex relaxation, which achieves remarkable efficacy in practice. However, the statistical stability guarantees of this approach are still far from optimal in the noisy setting, falling short of explaining its empirical success. Moreover, it is generally very challenging to pin down the distributions of the convex estimator, which presents a major roadblock in assessing the uncertainty, or “confidence”, of the obtained estimates. </p>
<p>Our work makes progress towards understanding stability and uncertainty quantification for noisy matrix completion. When the rank of the unknown matrix is a constant: (1) we demonstrate that the convex estimator achieves near-optimal estimation errors vis-à-vis random noise; (2) we develop a de-biased estimator that admits accurate distributional characterizations, thus enabling asymptotically optimal inference of the low-rank factors and the entries of the matrix. All of this is enabled by bridging convex relaxation with the nonconvex Burer-Monteiro approach, a seemingly distinct algorithmic paradigm that is provably stable against noise. </p>
<h2>Bio</h2>
<p>Cong Ma is a postdoctoral researcher in the Department of Electrical Engineering and Computer Sciences at UC Berkeley, advised by Professor Martin Wainwright. Previously, he obtained his Ph.D. at Princeton University under the supervision of Professor Yuxin Chen and Professor Jianqing Fan. His research interest lies in mathematics of data science, high-dimensional statistics, convex and nonconvex optimization. </p>
<div id="footer">
<div id="footer-text">
Page generated 2021-02-02 17:56:11 PST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
