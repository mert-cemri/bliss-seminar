<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Sharon Li (Wisconsin-Madison)</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Seminar&nbsp;home</a></div>
<div class="menu-item"><a href="past.html">Past&nbsp;Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Sharon Li (Wisconsin-Madison)</h1>
</div>
<p>Oct 19, 2020</p>
<h2>Title and Abstract</h2>
<p><b>Reliable Open-World Learning Against Out-of-distribution Data</b><br />
<br />
The real world is open and full of unknowns, presenting significant challenges for AI systems that must reliably handle diverse, and sometimes anomalous inputs. Out-of-distribution (OOD) uncertainty arises when a machine learning model sees a test-time input that differs from its training data, and thus should not be predicted by the model. As ML is used for more safety-critical domains, the abilities to handle out-of-distribution data are central in building open-world learning systems. In this talk, I will talk about methods, challenges, and opportunities towards building ROWL (Reliable Open-World Learning). To tackle these challenges, I will first describe mechanisms that improve OOD uncertainty estimation by using calibrated softmax score and input processing. I will then talk about the recent advancement of an energy-based OOD detection framework, which produces a theoretically meaningful measurement that is aligned with the probability density of the input data. We show that energy score is less susceptible to softmax's overconfidence issue, and leads to superior performance on common OOD detection benchmarks. Lastly, I will discuss how to robustify the out-of-distribution detection algorithms, in the presence of adversarial and physical-world plausible image perturbations.</p>
<h2>Bio</h2>
<p>Sharon Yixuan Li is an Assistant Professor in the Department of Computer Sciences at the University of Wisconsin-Madison. Previously, she was a postdoctoral researcher at Stanford University's Computer Science Department, where she worked with Chris RÃ©. She obtained her Ph.D. from Cornell University in 2017, advised by John E. Hopcroft, Kilian Q. Weinberger, and Thorsten Joachims. She served as Program Chair and a founding organizer of the ICML Workshop on Robustness and Uncertainty in Deep Learning (UDL) in 2019 and 2020. She has spent time at Google AI twice as an intern, and Facebook AI as a Research Scientist. She was named 30 Under 30 Rising Stars in AI in 2019, and Forbes 30Under30 in Science in 2020. Website: http:<i></i>pages.cs.wisc.edu<i>&nbsp;sharonli</i></p>
<div id="footer">
<div id="footer-text">
Page generated 2020-11-05 18:13:32 PST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
