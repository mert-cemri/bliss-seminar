<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Alekh Agarwal (Microsoft Research)</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Seminar&nbsp;home</a></div>
<div class="menu-item"><a href="past.html">Past&nbsp;Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Alekh Agarwal (Microsoft Research)</h1>
</div>
<p>May 14, 2021</p>
<h2>Title and Abstract</h2>
<p><b>Towards a Theory of Representation Learning for Reinforcement Learning</b><br />
<br /></p>
<p>Provably sample-efficient reinforcement learning from rich observational inputs remains a key open challenge in research. While impressive recent advances have allowed the use of linear modelling while carrying out sample-efficient exploration and learning, the handling of more general non-linear models remains limited. In this talk, we study reinforcement learning using linear models, where the features underlying the linear model are learned, rather than apriori specified. While the broader question of representation learning for useful embeddings of complex data has seen tremendous progress, doing so in reinforcement learning presents additional challenges: good representations cannot be discovered without adequate exploration, but effective exploration is challenging in the absence of good representations.</p>
<p>Concretely, we study this question in the context of low-rank MDPs <a href="Jiang" target=&ldquo;blank&rdquo;>et al., 2017, Jin et al., 2019, Yang and Wang, 2019</a>, where the features underlying a state-action pair are not assumed to be known, unlike most prior works. We develop two styles of methods, model-based and model-free. For the model-based method, we learn an approximate factorization of the transition model, plan within the model to obtain a fresh exploratory policy and then update our factorization with additional data. In the model-free technique, we learn features so that quantities such as value functions at subsequent states can be predicted linearly in those features. In both approaches, we address the intricate coupling between exploration and representation learning, and provide sample complexity guarantees. More details can be found at https:<i></i>arxiv.org<i>abs</i>2006.10814 and https:<i></i>arxiv.org<i>abs</i>2102.07035.</p>
<p><a href="Based" target=&ldquo;blank&rdquo;>on joint work with Jingling Chen, Nan Jiang, Sham Kakade, Akshay Krishnamurthy, Aditya Modi and Wen Sun</a>  </p>
<h2>Bio</h2>
<p>Alekh Agarwal is a Principal Research Manager at Microsoft Research Redmond, where he leads the group on Reinforcement Learning. He has been at Microsoft Research since completing his PhD from UC Berkeley in 2012, spending six years in the New York City lab, before moving to Redmond. Alekh's research has spanned many areas of machine learning including large-scale and distributed optimization, high-dimensional statistics, online learning, and most recently reinforcement learning. He focuses on designing theoretically sound methods which lend themselves to practice, and his work at Microsoft has resulted in the creation of a new Azure service (https:<i></i>aka.ms/personalizer) that operationalizes some of his reinforcement learning research. His work has been recognized with a NeurIPS best paper award and an ACM SIGAI Industry Impact award for his work on the Azure Personalization Service</p>
<div id="footer">
<div id="footer-text">
Page generated 2021-11-01 19:52:37 PDT, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
